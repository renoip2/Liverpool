{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....: FEATURE LIST :....\n",
      "['signal', 'signal_batch_min', 'signal_batch_max', 'signal_batch_std', 'signal_batch_mean', 'mean_abs_chg_batch', 'range_batch', 'maxtomin_batch', 'signal_batch_5k_min', 'signal_batch_5k_max', 'signal_batch_5k_std', 'signal_batch_5k_mean', 'mean_abs_chg_batch_5k', 'abs_max_batch_5k', 'abs_min_batch_5k', 'range_batch_5k', 'maxtomin_batch_5k', 'abs_avg_batch_5k', 'signal_shift+1', 'signal_shift-1', 'signal_batch_max_msignal', 'signal_batch_std_msignal', 'mean_abs_chg_batch_msignal', 'abs_max_batch_msignal', 'abs_min_batch_msignal', 'range_batch_msignal', 'maxtomin_batch_msignal', 'abs_avg_batch_msignal', 'signal_shift+1_msignal', 'signal_shift-1_msignal', 'signal_batch_5k_min_msignal', 'signal_batch_5k_max_msignal', 'signal_batch_5k_std_msignal', 'signal_batch_5k_mean_msignal', 'mean_abs_chg_batch_5k_msignal', 'abs_max_batch_5k_msignal', 'abs_min_batch_5k_msignal', 'maxtomin_batch_5k_msignal', 'abs_avg_batch_5k_msignal', 'signal_shift+2', 'signal_shift-2']\n",
      "====== Fold 1 of 5 ======\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 1.70175\tvalid_1's rmse: 1.70107\n",
      "[100]\ttraining's rmse: 1.09135\tvalid_1's rmse: 1.09102\n",
      "[150]\ttraining's rmse: 0.707017\tvalid_1's rmse: 0.706973\n",
      "[200]\ttraining's rmse: 0.46844\tvalid_1's rmse: 0.468668\n",
      "[250]\ttraining's rmse: 0.324811\tvalid_1's rmse: 0.325351\n",
      "[300]\ttraining's rmse: 0.242975\tvalid_1's rmse: 0.243843\n",
      "[350]\ttraining's rmse: 0.199951\tvalid_1's rmse: 0.201117\n",
      "[400]\ttraining's rmse: 0.179021\tvalid_1's rmse: 0.180436\n",
      "[450]\ttraining's rmse: 0.169303\tvalid_1's rmse: 0.170923\n",
      "[500]\ttraining's rmse: 0.164721\tvalid_1's rmse: 0.16651\n",
      "[550]\ttraining's rmse: 0.162428\tvalid_1's rmse: 0.164397\n",
      "[600]\ttraining's rmse: 0.161159\tvalid_1's rmse: 0.163308\n",
      "[650]\ttraining's rmse: 0.160369\tvalid_1's rmse: 0.162706\n",
      "[700]\ttraining's rmse: 0.159772\tvalid_1's rmse: 0.162298\n",
      "[750]\ttraining's rmse: 0.15932\tvalid_1's rmse: 0.162026\n",
      "[800]\ttraining's rmse: 0.158925\tvalid_1's rmse: 0.161833\n",
      "[850]\ttraining's rmse: 0.158556\tvalid_1's rmse: 0.16166\n",
      "[900]\ttraining's rmse: 0.158238\tvalid_1's rmse: 0.161569\n",
      "[950]\ttraining's rmse: 0.157948\tvalid_1's rmse: 0.161492\n",
      "[1000]\ttraining's rmse: 0.157664\tvalid_1's rmse: 0.161412\n",
      "[1050]\ttraining's rmse: 0.157412\tvalid_1's rmse: 0.161348\n",
      "[1100]\ttraining's rmse: 0.157183\tvalid_1's rmse: 0.161298\n",
      "[1150]\ttraining's rmse: 0.156964\tvalid_1's rmse: 0.161253\n",
      "[1200]\ttraining's rmse: 0.156758\tvalid_1's rmse: 0.161207\n",
      "[1250]\ttraining's rmse: 0.156564\tvalid_1's rmse: 0.161169\n",
      "[1300]\ttraining's rmse: 0.156372\tvalid_1's rmse: 0.161137\n",
      "[1350]\ttraining's rmse: 0.156184\tvalid_1's rmse: 0.161105\n",
      "[1400]\ttraining's rmse: 0.155999\tvalid_1's rmse: 0.161071\n",
      "[1450]\ttraining's rmse: 0.155819\tvalid_1's rmse: 0.161036\n",
      "[1500]\ttraining's rmse: 0.155643\tvalid_1's rmse: 0.161\n",
      "[1550]\ttraining's rmse: 0.155469\tvalid_1's rmse: 0.160975\n",
      "[1600]\ttraining's rmse: 0.155302\tvalid_1's rmse: 0.160951\n",
      "[1650]\ttraining's rmse: 0.155142\tvalid_1's rmse: 0.16093\n",
      "[1700]\ttraining's rmse: 0.154985\tvalid_1's rmse: 0.160913\n",
      "[1750]\ttraining's rmse: 0.154831\tvalid_1's rmse: 0.160894\n",
      "[1800]\ttraining's rmse: 0.154677\tvalid_1's rmse: 0.160874\n",
      "[1850]\ttraining's rmse: 0.154526\tvalid_1's rmse: 0.160859\n",
      "[1900]\ttraining's rmse: 0.154381\tvalid_1's rmse: 0.160847\n",
      "[1950]\ttraining's rmse: 0.154234\tvalid_1's rmse: 0.160836\n",
      "[2000]\ttraining's rmse: 0.154081\tvalid_1's rmse: 0.160822\n",
      "[2050]\ttraining's rmse: 0.153934\tvalid_1's rmse: 0.160808\n",
      "[2100]\ttraining's rmse: 0.153788\tvalid_1's rmse: 0.16079\n",
      "[2150]\ttraining's rmse: 0.153644\tvalid_1's rmse: 0.160774\n",
      "[2200]\ttraining's rmse: 0.153502\tvalid_1's rmse: 0.160754\n",
      "[2250]\ttraining's rmse: 0.153362\tvalid_1's rmse: 0.160735\n",
      "[2300]\ttraining's rmse: 0.153232\tvalid_1's rmse: 0.160727\n",
      "[2350]\ttraining's rmse: 0.153096\tvalid_1's rmse: 0.160714\n",
      "[2400]\ttraining's rmse: 0.152961\tvalid_1's rmse: 0.160705\n",
      "[2450]\ttraining's rmse: 0.152826\tvalid_1's rmse: 0.160694\n",
      "[2500]\ttraining's rmse: 0.152694\tvalid_1's rmse: 0.160679\n",
      "[2550]\ttraining's rmse: 0.152557\tvalid_1's rmse: 0.160663\n",
      "[2600]\ttraining's rmse: 0.152424\tvalid_1's rmse: 0.160652\n",
      "[2650]\ttraining's rmse: 0.152289\tvalid_1's rmse: 0.160644\n",
      "[2700]\ttraining's rmse: 0.152159\tvalid_1's rmse: 0.160635\n",
      "[2750]\ttraining's rmse: 0.152028\tvalid_1's rmse: 0.160626\n",
      "[2800]\ttraining's rmse: 0.151898\tvalid_1's rmse: 0.160621\n",
      "[2850]\ttraining's rmse: 0.151771\tvalid_1's rmse: 0.160618\n",
      "[2900]\ttraining's rmse: 0.15164\tvalid_1's rmse: 0.160614\n",
      "[2950]\ttraining's rmse: 0.151511\tvalid_1's rmse: 0.160606\n",
      "[3000]\ttraining's rmse: 0.151384\tvalid_1's rmse: 0.1606\n",
      "[3050]\ttraining's rmse: 0.151254\tvalid_1's rmse: 0.160595\n",
      "[3100]\ttraining's rmse: 0.151125\tvalid_1's rmse: 0.160588\n",
      "[3150]\ttraining's rmse: 0.150995\tvalid_1's rmse: 0.160579\n",
      "[3200]\ttraining's rmse: 0.150863\tvalid_1's rmse: 0.160576\n",
      "[3250]\ttraining's rmse: 0.150731\tvalid_1's rmse: 0.160572\n",
      "[3300]\ttraining's rmse: 0.150598\tvalid_1's rmse: 0.160566\n",
      "[3350]\ttraining's rmse: 0.150474\tvalid_1's rmse: 0.160563\n",
      "[3400]\ttraining's rmse: 0.150349\tvalid_1's rmse: 0.160557\n",
      "[3450]\ttraining's rmse: 0.150218\tvalid_1's rmse: 0.160551\n",
      "[3500]\ttraining's rmse: 0.150094\tvalid_1's rmse: 0.16055\n",
      "[3550]\ttraining's rmse: 0.149978\tvalid_1's rmse: 0.160546\n",
      "[3600]\ttraining's rmse: 0.149857\tvalid_1's rmse: 0.160541\n",
      "[3650]\ttraining's rmse: 0.149736\tvalid_1's rmse: 0.160537\n",
      "[3700]\ttraining's rmse: 0.149614\tvalid_1's rmse: 0.160533\n",
      "[3750]\ttraining's rmse: 0.149486\tvalid_1's rmse: 0.160527\n",
      "[3800]\ttraining's rmse: 0.149361\tvalid_1's rmse: 0.160523\n",
      "[3850]\ttraining's rmse: 0.149242\tvalid_1's rmse: 0.160522\n",
      "[3900]\ttraining's rmse: 0.149117\tvalid_1's rmse: 0.160515\n",
      "[3950]\ttraining's rmse: 0.148998\tvalid_1's rmse: 0.160512\n",
      "[4000]\ttraining's rmse: 0.148882\tvalid_1's rmse: 0.160509\n",
      "[4050]\ttraining's rmse: 0.148756\tvalid_1's rmse: 0.160503\n",
      "[4100]\ttraining's rmse: 0.148628\tvalid_1's rmse: 0.160499\n",
      "[4150]\ttraining's rmse: 0.148505\tvalid_1's rmse: 0.160493\n",
      "[4200]\ttraining's rmse: 0.148382\tvalid_1's rmse: 0.16049\n",
      "[4250]\ttraining's rmse: 0.14826\tvalid_1's rmse: 0.160488\n",
      "Early stopping, best iteration is:\n",
      "[4237]\ttraining's rmse: 0.148292\tvalid_1's rmse: 0.160486\n",
      "Fold 1 - validation f1: 0.93555\n",
      "Fold 1 - validation rmse: 0.18986\n",
      "====== Fold 2 of 5 ======\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 1.70114\tvalid_1's rmse: 1.70342\n",
      "[100]\ttraining's rmse: 1.09095\tvalid_1's rmse: 1.0924\n",
      "[150]\ttraining's rmse: 0.706772\tvalid_1's rmse: 0.70779\n",
      "[200]\ttraining's rmse: 0.468257\tvalid_1's rmse: 0.469109\n",
      "[250]\ttraining's rmse: 0.324641\tvalid_1's rmse: 0.32555\n",
      "[300]\ttraining's rmse: 0.242847\tvalid_1's rmse: 0.243971\n",
      "[350]\ttraining's rmse: 0.199809\tvalid_1's rmse: 0.201225\n",
      "[400]\ttraining's rmse: 0.178899\tvalid_1's rmse: 0.180602\n",
      "[450]\ttraining's rmse: 0.16918\tvalid_1's rmse: 0.17113\n",
      "[500]\ttraining's rmse: 0.164587\tvalid_1's rmse: 0.166751\n",
      "[550]\ttraining's rmse: 0.16231\tvalid_1's rmse: 0.164681\n",
      "[600]\ttraining's rmse: 0.161057\tvalid_1's rmse: 0.163617\n",
      "[650]\ttraining's rmse: 0.160253\tvalid_1's rmse: 0.163003\n",
      "[700]\ttraining's rmse: 0.159654\tvalid_1's rmse: 0.162593\n",
      "[750]\ttraining's rmse: 0.159207\tvalid_1's rmse: 0.162342\n",
      "[800]\ttraining's rmse: 0.158823\tvalid_1's rmse: 0.162149\n",
      "[850]\ttraining's rmse: 0.158477\tvalid_1's rmse: 0.162003\n",
      "[900]\ttraining's rmse: 0.158163\tvalid_1's rmse: 0.161908\n",
      "[950]\ttraining's rmse: 0.15787\tvalid_1's rmse: 0.161816\n",
      "[1000]\ttraining's rmse: 0.157591\tvalid_1's rmse: 0.161724\n",
      "[1050]\ttraining's rmse: 0.157339\tvalid_1's rmse: 0.161661\n",
      "[1100]\ttraining's rmse: 0.157105\tvalid_1's rmse: 0.16161\n",
      "[1150]\ttraining's rmse: 0.156884\tvalid_1's rmse: 0.161561\n",
      "[1200]\ttraining's rmse: 0.156676\tvalid_1's rmse: 0.16152\n",
      "[1250]\ttraining's rmse: 0.156477\tvalid_1's rmse: 0.161486\n",
      "[1300]\ttraining's rmse: 0.156275\tvalid_1's rmse: 0.161452\n",
      "[1350]\ttraining's rmse: 0.156084\tvalid_1's rmse: 0.161419\n",
      "[1400]\ttraining's rmse: 0.155898\tvalid_1's rmse: 0.161391\n",
      "[1450]\ttraining's rmse: 0.155718\tvalid_1's rmse: 0.161365\n",
      "[1500]\ttraining's rmse: 0.155544\tvalid_1's rmse: 0.161343\n",
      "[1550]\ttraining's rmse: 0.155373\tvalid_1's rmse: 0.161324\n",
      "[1600]\ttraining's rmse: 0.155207\tvalid_1's rmse: 0.161303\n",
      "[1650]\ttraining's rmse: 0.155045\tvalid_1's rmse: 0.161284\n",
      "[1700]\ttraining's rmse: 0.154886\tvalid_1's rmse: 0.161264\n",
      "[1750]\ttraining's rmse: 0.15473\tvalid_1's rmse: 0.161249\n",
      "[1800]\ttraining's rmse: 0.154576\tvalid_1's rmse: 0.161231\n",
      "[1850]\ttraining's rmse: 0.154418\tvalid_1's rmse: 0.161204\n",
      "[1900]\ttraining's rmse: 0.154262\tvalid_1's rmse: 0.161182\n",
      "[1950]\ttraining's rmse: 0.154113\tvalid_1's rmse: 0.161167\n",
      "[2000]\ttraining's rmse: 0.153967\tvalid_1's rmse: 0.161152\n",
      "[2050]\ttraining's rmse: 0.153821\tvalid_1's rmse: 0.161136\n",
      "[2100]\ttraining's rmse: 0.153677\tvalid_1's rmse: 0.161122\n",
      "[2150]\ttraining's rmse: 0.153529\tvalid_1's rmse: 0.161105\n",
      "[2200]\ttraining's rmse: 0.153381\tvalid_1's rmse: 0.161093\n",
      "[2250]\ttraining's rmse: 0.153234\tvalid_1's rmse: 0.161085\n",
      "[2300]\ttraining's rmse: 0.153087\tvalid_1's rmse: 0.161075\n",
      "[2350]\ttraining's rmse: 0.152948\tvalid_1's rmse: 0.161065\n",
      "[2400]\ttraining's rmse: 0.152804\tvalid_1's rmse: 0.161049\n",
      "[2450]\ttraining's rmse: 0.15267\tvalid_1's rmse: 0.161038\n",
      "[2500]\ttraining's rmse: 0.152528\tvalid_1's rmse: 0.161025\n",
      "[2550]\ttraining's rmse: 0.152394\tvalid_1's rmse: 0.161011\n",
      "[2600]\ttraining's rmse: 0.152251\tvalid_1's rmse: 0.160995\n",
      "[2650]\ttraining's rmse: 0.152115\tvalid_1's rmse: 0.160983\n",
      "[2700]\ttraining's rmse: 0.151978\tvalid_1's rmse: 0.160975\n",
      "[2750]\ttraining's rmse: 0.151845\tvalid_1's rmse: 0.160966\n",
      "[2800]\ttraining's rmse: 0.151708\tvalid_1's rmse: 0.160956\n",
      "[2850]\ttraining's rmse: 0.151574\tvalid_1's rmse: 0.160946\n",
      "[2900]\ttraining's rmse: 0.151439\tvalid_1's rmse: 0.160937\n",
      "[2950]\ttraining's rmse: 0.151306\tvalid_1's rmse: 0.16093\n",
      "[3000]\ttraining's rmse: 0.151179\tvalid_1's rmse: 0.160919\n",
      "[3050]\ttraining's rmse: 0.15105\tvalid_1's rmse: 0.160908\n",
      "[3100]\ttraining's rmse: 0.15092\tvalid_1's rmse: 0.160901\n",
      "[3150]\ttraining's rmse: 0.150793\tvalid_1's rmse: 0.160892\n",
      "[3200]\ttraining's rmse: 0.150664\tvalid_1's rmse: 0.160887\n",
      "[3250]\ttraining's rmse: 0.150538\tvalid_1's rmse: 0.160881\n",
      "[3300]\ttraining's rmse: 0.150408\tvalid_1's rmse: 0.160878\n",
      "[3350]\ttraining's rmse: 0.150277\tvalid_1's rmse: 0.160868\n",
      "[3400]\ttraining's rmse: 0.150147\tvalid_1's rmse: 0.160861\n",
      "[3450]\ttraining's rmse: 0.150016\tvalid_1's rmse: 0.160851\n",
      "[3500]\ttraining's rmse: 0.149885\tvalid_1's rmse: 0.160846\n",
      "[3550]\ttraining's rmse: 0.149754\tvalid_1's rmse: 0.160839\n",
      "[3600]\ttraining's rmse: 0.149627\tvalid_1's rmse: 0.160832\n",
      "[3650]\ttraining's rmse: 0.149503\tvalid_1's rmse: 0.160825\n",
      "[3700]\ttraining's rmse: 0.149385\tvalid_1's rmse: 0.160819\n",
      "[3750]\ttraining's rmse: 0.149271\tvalid_1's rmse: 0.160814\n",
      "[3800]\ttraining's rmse: 0.149149\tvalid_1's rmse: 0.160808\n",
      "[3850]\ttraining's rmse: 0.149031\tvalid_1's rmse: 0.160802\n",
      "[3900]\ttraining's rmse: 0.148915\tvalid_1's rmse: 0.160797\n",
      "[3950]\ttraining's rmse: 0.148805\tvalid_1's rmse: 0.160794\n",
      "[4000]\ttraining's rmse: 0.148692\tvalid_1's rmse: 0.160793\n",
      "[4050]\ttraining's rmse: 0.148581\tvalid_1's rmse: 0.160787\n",
      "[4100]\ttraining's rmse: 0.148468\tvalid_1's rmse: 0.160786\n",
      "[4150]\ttraining's rmse: 0.148358\tvalid_1's rmse: 0.16078\n",
      "[4200]\ttraining's rmse: 0.148241\tvalid_1's rmse: 0.160776\n",
      "[4250]\ttraining's rmse: 0.148124\tvalid_1's rmse: 0.160769\n",
      "[4300]\ttraining's rmse: 0.148008\tvalid_1's rmse: 0.160765\n",
      "[4350]\ttraining's rmse: 0.147888\tvalid_1's rmse: 0.160762\n",
      "[4400]\ttraining's rmse: 0.147777\tvalid_1's rmse: 0.160757\n",
      "[4450]\ttraining's rmse: 0.147658\tvalid_1's rmse: 0.16075\n",
      "[4500]\ttraining's rmse: 0.147543\tvalid_1's rmse: 0.160747\n",
      "[4550]\ttraining's rmse: 0.147434\tvalid_1's rmse: 0.160743\n",
      "[4600]\ttraining's rmse: 0.147323\tvalid_1's rmse: 0.160742\n",
      "Early stopping, best iteration is:\n",
      "[4570]\ttraining's rmse: 0.147392\tvalid_1's rmse: 0.160741\n",
      "Fold 2 - validation f1: 0.93630\n",
      "Fold 2 - validation rmse: 0.19032\n",
      "====== Fold 3 of 5 ======\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Baseline Model Pipeline:\n",
    "    - Baseline LGBM with some batch features\n",
    "    - 5KFold Shuffled\n",
    "    - Regression (code also allows for multiclass)\n",
    "    - OOF / Predictions and Feature importances saved as CSV\n",
    "    - Feature importance plot.\n",
    "    \n",
    "Updated in this version:\n",
    "    - +/-2 shifts\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import lightgbm as lgb\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, mean_squared_error, f1_score\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "###########\n",
    "# SETTINGS\n",
    "###########\n",
    "\n",
    "MODEL = 'LGBM_model'#os.path.basename(__file__).split('.')[0]\n",
    "\n",
    "TARGET = 'open_channels'\n",
    "\n",
    "TOTAL_FOLDS = 5\n",
    "RANDOM_SEED = 529\n",
    "MODEL_TYPE = 'LGBM'\n",
    "LEARNING_RATE = 0.009\n",
    "SHUFFLE = True\n",
    "NUM_BOOST_ROUND = 500_000\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "N_THREADS = -1\n",
    "OBJECTIVE = 'regression'\n",
    "METRIC = 'rmse'\n",
    "NUM_LEAVES = 2**8+1\n",
    "MAX_DEPTH = -1\n",
    "FEATURE_FRACTION = 1\n",
    "BAGGING_FRACTION = 1\n",
    "BAGGING_FREQ = 0\n",
    "\n",
    "####################\n",
    "# READING IN FILES\n",
    "####################\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "ss = pd.read_csv('sample_submission.csv')\n",
    "train['train'] = True\n",
    "test['train'] = False\n",
    "tt = pd.concat([train, test], sort=False).reset_index(drop=True)\n",
    "tt['train'] = tt['train'].astype('bool')\n",
    "\n",
    "###########\n",
    "# TRACKING\n",
    "###########\n",
    "\n",
    "run_id = \"{:%m%d_%H%M}\".format(datetime.now())\n",
    "\n",
    "\n",
    "def update_tracking(\n",
    "        run_id, field, value, csv_file=\"./tracking.csv\",\n",
    "        integer=False, digits=None, nround=6,\n",
    "        drop_broken_runs=False):\n",
    "    \"\"\"\n",
    "    Tracking function for keep track of model parameters and\n",
    "    CV scores. `integer` forces the value to be an int.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file, index_col=[0])\n",
    "    except:\n",
    "        df = pd.DataFrame()\n",
    "    if drop_broken_runs:\n",
    "        df = df.dropna(subset=['1_f1'])\n",
    "    if integer:\n",
    "        value = round(value)\n",
    "    elif digits is not None:\n",
    "        value = round(value, digits)\n",
    "    df.loc[run_id, field] = value  # Model number is index\n",
    "    df = df.round(nround)\n",
    "    df.to_csv(csv_file)\n",
    "\n",
    "\n",
    "# Update Tracking\n",
    "update_tracking(run_id, 'model_number', MODEL)\n",
    "update_tracking(run_id, 'model_type', MODEL_TYPE)\n",
    "update_tracking(run_id, 'seed', RANDOM_SEED, integer=True)\n",
    "update_tracking(run_id, 'nfolds', TOTAL_FOLDS, integer=True)\n",
    "update_tracking(run_id, 'lr', LEARNING_RATE)\n",
    "update_tracking(run_id, 'shuffle', SHUFFLE)\n",
    "update_tracking(run_id, 'boost_rounds', NUM_BOOST_ROUND)\n",
    "update_tracking(run_id, 'es_rounds', EARLY_STOPPING_ROUNDS)\n",
    "update_tracking(run_id, 'threads', N_THREADS)\n",
    "update_tracking(run_id, 'objective', OBJECTIVE)\n",
    "update_tracking(run_id, 'metric', METRIC)\n",
    "update_tracking(run_id, 'num_leaves', NUM_LEAVES)\n",
    "update_tracking(run_id, 'max_depth', MAX_DEPTH)\n",
    "update_tracking(run_id, 'feature_fraction', FEATURE_FRACTION)\n",
    "update_tracking(run_id, 'bagging_fraction', BAGGING_FRACTION)\n",
    "update_tracking(run_id, 'bagging_freq', BAGGING_FREQ)\n",
    "\n",
    "###########\n",
    "# FEATURES\n",
    "###########\n",
    "\n",
    "# # Include batch\n",
    "tt = tt.sort_values(by=['time']).reset_index(drop=True)\n",
    "tt.index = ((tt.time * 10_000) - 1).values\n",
    "tt['batch'] = tt.index // 50_000\n",
    "tt['batch_index'] = tt.index - (tt.batch * 50_000)\n",
    "tt['batch_slices'] = tt['batch_index'] // 5_000\n",
    "tt['batch_slices2'] = tt.apply(lambda r: '_'.join(\n",
    "    [str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n",
    "\n",
    "# 50_000 Batch Features\n",
    "tt['signal_batch_min'] = tt.groupby('batch')['signal'].transform('min')\n",
    "tt['signal_batch_max'] = tt.groupby('batch')['signal'].transform('max')\n",
    "tt['signal_batch_std'] = tt.groupby('batch')['signal'].transform('std')\n",
    "tt['signal_batch_mean'] = tt.groupby('batch')['signal'].transform('mean')\n",
    "tt['mean_abs_chg_batch'] = tt.groupby(['batch'])['signal'].transform(\n",
    "    lambda x: np.mean(np.abs(np.diff(x))))\n",
    "tt['abs_max_batch'] = tt.groupby(\n",
    "    ['batch'])['signal'].transform(lambda x: np.max(np.abs(x)))\n",
    "tt['abs_min_batch'] = tt.groupby(\n",
    "    ['batch'])['signal'].transform(lambda x: np.min(np.abs(x)))\n",
    "\n",
    "tt['range_batch'] = tt['signal_batch_max'] - tt['signal_batch_min']\n",
    "tt['maxtomin_batch'] = tt['signal_batch_max'] / tt['signal_batch_min']\n",
    "tt['abs_avg_batch'] = (tt['abs_min_batch'] + tt['abs_max_batch']) / 2\n",
    "\n",
    "# 5_000 Batch Features\n",
    "tt['signal_batch_5k_min'] = tt.groupby(\n",
    "    'batch_slices2')['signal'].transform('min')\n",
    "tt['signal_batch_5k_max'] = tt.groupby(\n",
    "    'batch_slices2')['signal'].transform('max')\n",
    "tt['signal_batch_5k_std'] = tt.groupby(\n",
    "    'batch_slices2')['signal'].transform('std')\n",
    "tt['signal_batch_5k_mean'] = tt.groupby(\n",
    "    'batch_slices2')['signal'].transform('mean')\n",
    "tt['mean_abs_chg_batch_5k'] = tt.groupby(['batch_slices2'])[\n",
    "    'signal'].transform(lambda x: np.mean(np.abs(np.diff(x))))\n",
    "tt['abs_max_batch_5k'] = tt.groupby(['batch_slices2'])[\n",
    "    'signal'].transform(lambda x: np.max(np.abs(x)))\n",
    "tt['abs_min_batch_5k'] = tt.groupby(['batch_slices2'])[\n",
    "    'signal'].transform(lambda x: np.min(np.abs(x)))\n",
    "\n",
    "tt['range_batch_5k'] = tt['signal_batch_5k_max'] - tt['signal_batch_5k_min']\n",
    "tt['maxtomin_batch_5k'] = tt['signal_batch_5k_max'] / tt['signal_batch_5k_min']\n",
    "tt['abs_avg_batch_5k'] = (tt['abs_min_batch_5k'] + tt['abs_max_batch_5k']) / 2\n",
    "\n",
    "\n",
    "# add shifts\n",
    "tt['signal_shift+1'] = tt.groupby(['batch']).shift(1)['signal']\n",
    "tt['signal_shift-1'] = tt.groupby(['batch']).shift(-1)['signal']\n",
    "tt['signal_shift+2'] = tt.groupby(['batch']).shift(2)['signal']\n",
    "tt['signal_shift-2'] = tt.groupby(['batch']).shift(-2)['signal']\n",
    "\n",
    "for c in ['signal_batch_min', 'signal_batch_max',\n",
    "          'signal_batch_std', 'signal_batch_mean',\n",
    "          'mean_abs_chg_batch', 'abs_max_batch',\n",
    "          'abs_min_batch',\n",
    "          'range_batch', 'maxtomin_batch', 'abs_avg_batch',\n",
    "          'signal_shift+1', 'signal_shift-1',\n",
    "          'signal_batch_5k_min', 'signal_batch_5k_max',\n",
    "          'signal_batch_5k_std',\n",
    "          'signal_batch_5k_mean', 'mean_abs_chg_batch_5k',\n",
    "          'abs_max_batch_5k', 'abs_min_batch_5k',\n",
    "          'range_batch_5k', 'maxtomin_batch_5k',\n",
    "          'abs_avg_batch_5k','signal_shift+2','signal_shift-2']:\n",
    "    tt[f'{c}_msignal'] = tt[c] - tt['signal']\n",
    "\n",
    "\n",
    "# FEATURES = [f for f in tt.columns if f not in ['open_channels','index','time','train','batch',\n",
    "#                                                'batch_index','batch_slices','batch_slices2']]\n",
    "\n",
    "\n",
    "FEATURES = ['signal',\n",
    "            'signal_batch_min',\n",
    "            'signal_batch_max',\n",
    "            'signal_batch_std',\n",
    "            'signal_batch_mean',\n",
    "            'mean_abs_chg_batch',\n",
    "            #'abs_max_batch',\n",
    "            #'abs_min_batch',\n",
    "            #'abs_avg_batch',\n",
    "            'range_batch',\n",
    "            'maxtomin_batch',\n",
    "            'signal_batch_5k_min',\n",
    "            'signal_batch_5k_max',\n",
    "            'signal_batch_5k_std',\n",
    "            'signal_batch_5k_mean',\n",
    "            'mean_abs_chg_batch_5k',\n",
    "            'abs_max_batch_5k',\n",
    "            'abs_min_batch_5k',\n",
    "            'range_batch_5k',\n",
    "            'maxtomin_batch_5k',\n",
    "            'abs_avg_batch_5k',\n",
    "            'signal_shift+1',\n",
    "            'signal_shift-1',\n",
    "            # 'signal_batch_min_msignal',\n",
    "            'signal_batch_max_msignal',\n",
    "            'signal_batch_std_msignal',\n",
    "            # 'signal_batch_mean_msignal',\n",
    "            'mean_abs_chg_batch_msignal',\n",
    "            'abs_max_batch_msignal',\n",
    "            'abs_min_batch_msignal',\n",
    "            'range_batch_msignal',\n",
    "            'maxtomin_batch_msignal',\n",
    "            'abs_avg_batch_msignal',\n",
    "            'signal_shift+1_msignal',\n",
    "            'signal_shift-1_msignal',\n",
    "            'signal_batch_5k_min_msignal',\n",
    "            'signal_batch_5k_max_msignal',\n",
    "            'signal_batch_5k_std_msignal',\n",
    "            'signal_batch_5k_mean_msignal',\n",
    "            'mean_abs_chg_batch_5k_msignal',\n",
    "            'abs_max_batch_5k_msignal',\n",
    "            'abs_min_batch_5k_msignal',\n",
    "            #'range_batch_5k_msignal',\n",
    "            'maxtomin_batch_5k_msignal',\n",
    "            'abs_avg_batch_5k_msignal',\n",
    "            'signal_shift+2',\n",
    "            'signal_shift-2']\n",
    "\n",
    "print('....: FEATURE LIST :....')\n",
    "print([f for f in FEATURES])\n",
    "\n",
    "update_tracking(run_id, 'n_features', len(FEATURES), integer=True)\n",
    "update_tracking(run_id, 'target', TARGET)\n",
    "\n",
    "###########\n",
    "# Metric\n",
    "###########\n",
    "\n",
    "\n",
    "def lgb_Metric(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    print(preds.shape)\n",
    "    print(preds)\n",
    "    preds = np.argmax(preds, axis=0)\n",
    "#     score = metrics.cohen_kappa_score(labels, preds, weights = 'quadratic')\n",
    "    score = f1_score(labels, preds, average='macro')\n",
    "    return ('KaggleMetric', score, True)\n",
    "\n",
    "\n",
    "###########\n",
    "# MODEL\n",
    "###########\n",
    "tt['train'] = tt['train'].astype('bool')\n",
    "train = tt.query('train').copy()\n",
    "test = tt.query('not train').copy()\n",
    "train['open_channels'] = train['open_channels'].astype(int)\n",
    "X = train[FEATURES]\n",
    "X_test = test[FEATURES]\n",
    "y = train[TARGET].values\n",
    "sub = test[['time']].copy()\n",
    "groups = train['batch']\n",
    "\n",
    "if OBJECTIVE == 'multiclass':\n",
    "    NUM_CLASS = 11\n",
    "else:\n",
    "    NUM_CLASS = 1\n",
    "\n",
    "# define hyperparammeter (some random hyperparammeters)\n",
    "params = {'learning_rate': LEARNING_RATE,\n",
    "          'max_depth': MAX_DEPTH,\n",
    "          'num_leaves': NUM_LEAVES,\n",
    "          'feature_fraction': FEATURE_FRACTION,\n",
    "          'bagging_fraction': BAGGING_FRACTION,\n",
    "          'bagging_freq': BAGGING_FREQ,\n",
    "          'n_jobs': N_THREADS,\n",
    "          'seed': RANDOM_SEED,\n",
    "          'metric': METRIC,\n",
    "          'objective': OBJECTIVE,\n",
    "          'num_class': NUM_CLASS\n",
    "          }\n",
    "\n",
    "kfold = KFold(n_splits=TOTAL_FOLDS, shuffle=SHUFFLE, random_state=RANDOM_SEED)\n",
    "\n",
    "oof_df = train[['signal', 'open_channels']].copy()\n",
    "fi_df = pd.DataFrame(index=FEATURES)\n",
    "\n",
    "fold = 1  # init fold counter\n",
    "for tr_idx, val_idx in kfold.split(X, y, groups=groups):\n",
    "    print(f'====== Fold {fold:0.0f} of {TOTAL_FOLDS} ======')\n",
    "    X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "    train_set = lgb.Dataset(X_tr, y_tr)\n",
    "    val_set = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                      train_set,\n",
    "                      num_boost_round=NUM_BOOST_ROUND,\n",
    "                      early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                      valid_sets=[train_set, val_set],\n",
    "                      verbose_eval=50)\n",
    "    # feval=lgb_Metric)\n",
    "\n",
    "    if OBJECTIVE == 'multi_class':\n",
    "        preds = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        test_preds = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        test_preds = np.argmax(test_preds, axis=1)\n",
    "    elif OBJECTIVE == 'regression':\n",
    "        preds = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        preds = np.round(np.clip(preds, 0, 10)).astype(int)\n",
    "        test_preds = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        test_preds = np.round(np.clip(test_preds, 0, 10)).astype(int)\n",
    "\n",
    "    oof_df.loc[oof_df.iloc[val_idx].index, 'oof'] = preds\n",
    "    sub[f'open_channels_fold{fold}'] = test_preds\n",
    "\n",
    "    f1 = f1_score(oof_df.loc[oof_df.iloc[val_idx].index]['open_channels'],\n",
    "                  oof_df.loc[oof_df.iloc[val_idx].index]['oof'],\n",
    "                  average='macro')\n",
    "    rmse = np.sqrt(mean_squared_error(oof_df.loc[oof_df.index.isin(val_idx)]['open_channels'],\n",
    "                                      oof_df.loc[oof_df.index.isin(val_idx)]['oof']))\n",
    "\n",
    "    update_tracking(run_id, f'{fold}_best_iter', model.best_iteration, integer=True)\n",
    "    update_tracking(run_id, f'{fold}_rmse', rmse)\n",
    "    update_tracking(run_id, f'{fold}_f1', f1)\n",
    "    fi_df[f'importance_{fold}'] = model.feature_importance()\n",
    "    print(f'Fold {fold} - validation f1: {f1:0.5f}')\n",
    "    print(f'Fold {fold} - validation rmse: {rmse:0.5f}')\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "oof_f1 = f1_score(oof_df['open_channels'],\n",
    "                  oof_df['oof'],\n",
    "                  average='macro')\n",
    "oof_rmse = np.sqrt(mean_squared_error(oof_df['open_channels'],\n",
    "                                      oof_df['oof']))\n",
    "\n",
    "update_tracking(run_id, f'oof_f1', oof_f1)\n",
    "update_tracking(run_id, f'oof_rmse', oof_rmse)\n",
    "\n",
    "###############\n",
    "# SAVE RESULTS\n",
    "###############\n",
    "\n",
    "s_cols = [s for s in sub.columns if 'open_channels' in s]\n",
    "\n",
    "sub['open_channels'] = sub[s_cols].median(axis=1).astype(int)\n",
    "sub.to_csv(f'./pred_{MODEL}_{oof_f1:0.6}.csv', index=False)\n",
    "sub[['time', 'open_channels']].to_csv(f'./sub_{MODEL}_{oof_f1:0.10f}.csv',\n",
    "                                      index=False,\n",
    "                                      float_format='%0.4f')\n",
    "\n",
    "oof_df.to_csv(f'./oof_{MODEL}_{oof_f1:0.6}.csv', index=False)\n",
    "\n",
    "fi_df['importance'] = fi_df.sum(axis=1)\n",
    "fi_df.to_csv(f'./fi_{MODEL}_{oof_f1:0.6}.csv', index=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 30))\n",
    "fi_df.sort_values('importance')['importance'] \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 30),\n",
    "          title=f'{MODEL} - Feature Importance',\n",
    "          ax=ax)\n",
    "plt.savefig(f'./{MODEL}__{oof_f1:0.6}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
